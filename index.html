<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>ibl-mtm</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="icon" type="image/png" href="./index_files/icon.png">
    <link rel="stylesheet" href="./index_files/bootstrap.min.css">
    <link rel="stylesheet" href="./index_files/font-awesome.min.css">
    <link rel="stylesheet" href="./index_files/codemirror.min.css">
    <link rel="stylesheet" href="./index_files/app.css">
    <link rel="stylesheet" href="./index_files/bootstrap.min(1).css">

    <script type="text/javascript" async="" src="./index_files/analytics.js"></script>
    <script type="text/javascript" async="" src="./index_files/analytics(1).js"></script>
    <script async="" src="./index_files/js"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-110862391-3');
    </script>

    <script src="./index_files/jquery.min.js"></script>
    <script src="./index_files/bootstrap.min.js"></script>
    <script src="./index_files/codemirror.min.js"></script>
    <script src="./index_files/clipboard.min.js"></script>

    <script src="./index_files/app.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DG5ZZGKNKT"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DG5ZZGKNKT');
</script>        
    
<body data-gr-c-s-loaded="true">
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Towards a “universal translator” for neural dynamics at single-cell, single-spike resolution
            <br /><br />
            <small>
                Coming soon...
            </small>
            <br /><br />
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://yzhang511.github.io/">
                            Yizi Zhang.
                        </a><sup>1</sup>
                    </li>
                    <li>
                        <a href="https://ppwangyc.github.io">
                          Yanchen Wang
                        </a><sup>2</sup>
                    </li>                    
                   <li>
                        <a href="mailto:donatojb@mit.edu">
                            Donato Jiménez Benetó
                        </a><sup>3</sup>
                    </li>
                    <li>
                        <a href="mailto:zw3008@columbia.edu">
                            Zixuan Wang
                        </a><sup>1</sup>
                    </li> 
                    <li>
                        <a href="mailto:mazabou@gatech.edu">
                            Mehdi Azabou
                        </a><sup>4</sup>
                    </li> 
                    <li>
                        <a href="https://sites.google.com/mila.quebec/linc-lab/home">
                            Blake Richards
                        </a><sup>5,6</sup>
                    </li> 
                    <li>
                        <a href="https://pt.linkedin.com/in/olivier-winter-57681087">
                            Olivier Winter
                        </a><sup>7</sup>
                    </li> 
                    <li>
                        <a href="https://www.internationalbrainlab.com/">
                            The International Brain Laboratory
                        </a><sup>8</sup>
                    </li>   
                    <li>
                        <a href="https://dyerlab.gatech.edu/">
                            Eva Dyer
                        </a><sup>4</sup>
                    </li> 
                    <li>
                        <a href="http://www.stat.columbia.edu/~liam/">
                            Liam Paninski
                        </a><sup>1</sup>
                    </li>
                    <li>
                        <a href="https://colehurwitz.github.io/">
                            Cole Hurwitz
                        </a><sup>1</sup>
                    </li>                       
                </ul>
            </div>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <sup>1</sup>Columbia University
                    </li>
                    <br>
                    <li>
                        <sup>2</sup>Standford University
                    </li>
                    <br>
                    <li>
                        <sup>3</sup>Universitat Politècnica de Catalunya
                    </li>
                    <li>
                        <sup>4</sup>Georgia Institute of Technology
                    </li>
                    <li>
                        <sup>5</sup>Mila
                    </li>
                    <li>
                        <sup>6</sup>McGill University
                    </li>
                    <li>
                        <sup>7</sup>Champalimaud Foundation
                    </li>
                    <br>
                    <li>
                        <sup>8</sup>The International Brain Laboratory
                    </li>
                    <br>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="index_files/pdfs/brain_wide_self_supervised_neurips_2024.pdf" target='_blank'>
                        <img src="index_files/images/paper.png" height="80px"><br>
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/colehurwitz/IBL_foundation_model/">
                        <img src="./index_files/images/github_pad.png" height="80px"><br>
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://huggingface.co/ibl-foundation-model">
                        <img src="./index_files/images/hugging_face.png" height="80px"><br>
                            <h4><strong>HuggingFace</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="#BibTeX">
                        <img src="./index_files/images/bibtex.jpg" height="80px"><br>
                            <h4><strong>BibTeX</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview
                </h3>
                <img src="./index_files/images/figure_1.png" class="img-responsive" alt="overview"><br>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Neuroscience research has made immense progress over the last decade, but our understanding of the brain remains fragmented and piecemeal: the dream of probing an arbitrary brain region and automatically reading out the information encoded in its neural activity remains out of reach. In this work, we build towards a first foundation model for neural spiking data that can solve a diverse set of tasks across multiple brain areas. We introduce a novel self-supervised modeling approach for population activity in which the model alternates between masking out and reconstructing neural activity across different time steps, neurons, and brain regions. To evaluate our approach, we design unsupervised and supervised prediction tasks using the International Brain Laboratory repeated site dataset, which is comprised of Neuropixels recordings targeting the same brain locations across 48 animals and experimental sessions. The prediction tasks include single-neuron and region-level activity prediction, forward prediction, and behavior decoding. We demonstrate that our multi-task-masking (MtM) approach significantly improves the performance of current state-of-the-art population models and enables multi-task learning. We also show that by training on multiple animals, we can improve the generalization ability of the model to unseen animals, paving the way for a foundation model of the brain at single-cell, single-spike resolution.
                </p>
            </div>
        </div>
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Highlights
                </h3>
                <p class="text-justify">
                    <ul>
                        <li>
                            A novel multi-task-masking (MtM) approach which can be applied to multi-region datasets to successfully learn representations that lead to better downstream task performance.
                        </li>
                        <li>
                            A prompt-based approach for test-time adaptation which improves performance on a variety of downstream tasks during inference.
                        </li>
                        <li>
                            Scaling results that demonstrate that having data from more animals provides benefits on held-out animals and sessions as well as on unseen tasks.
                        </li>
                        <li>
                            A new multi-task, multi-region benchmark for evaluating foundation models of neural population activity.
                        </li>
                    </ul>
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Single-session
                </h3>
                <img src="./index_files/images/figure_2.png" class="img-responsive" alt="method"><br>
                <p class="text-justify">
                    <i>Comparison of the temporal masking baseline and the proposed MtM method for NDT1 on activity reconstruction and behavior decoding across 39 sessions.</i> Each point represents one session. For activity reconstruction, we report the average bps. For choice and whisker motion energy decoding, we report the average accuracy and R<sup>2</sup>, respectively, across all test trials.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Multi-session
                </h3>
                <img src="./index_files/images/figure_3.png" class="img-responsive" alt="result with sota"><br>
                <p class="text-justify">
                    <i>Fine-tuning performance comparison of NDT1-stitch pretrained with MtM vs. temporal masking for activity reconstruction and behavior decoding across 5 held-out sessions.</i> For activity reconstruction, each point shows the average bps across all neurons in a held-out session. For choice and whisker motion energy decoding, each point represents the average accuracy and R<sup>2</sup>, respectively, across all test trials in one session.
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Scale analysis
                </h3>
                <img src="./index_files/images/figure_4.png" class="img-responsive" alt="clustering analysis"><br>
                <p class="text-justify">
                    <i>Comparison of scaling curves between  NDT1-stitch pretrained with the MtM method vs. the temporal masking baseline.</i> The reported metrics - neuron-averaged bits per spike (bps), choice decoding accuracy, and whisker motion energy decoding R<sup>2</sup> - are averaged over all 5 held-out sessions. We fine-tune each pretrained model with its self-supervised loss (MtM or temporal) on the 5-heldout sessions and then evaluate with all of our metrics. "Num of Sessions" denotes the number of sessions used for pretraining.
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Behavior decoding from individual brain regions
                </h3>
                <img src="./index_files/images/figure_5.png" class="img-responsive" alt="zero-shot"><br>
                <p class="text-justify">
                    <i>Comparison of NDT1-stitch pretrained with the MtM method vs. the baseline temporal masking on behavior decoding from individual brain regions.</i> The rows display choice decoding accuracy and whisker motion energy decoding R<sup>2</sup>. Columns represent individual held-out sessions. Each point shows the behavior decoding performance when using neural activity from a specific brain region, with colors denoting different brain regions.
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Single neuron evaluation
                </h3>
                <img src="./index_files/images/figure_6.png" class="img-responsive" alt="zero-shot"><br>
                <p class="text-justify">
                    <b>Single neuron activity reconstruction analysis for NDT1 in one session.</b> To evaluate the reconstruction quality for each  neuron, multiple metrics are computed: Bits per spike (Bps), R<sup>2</sup> between the ground truth and predicted peristimulus time histogram (PSTH R<sup>2</sup>), and the single-trial R<sup>2</sup> averaged across all trials (Trial average R<sup>2</sup>). Each point represents one neuron, with the color indicating the neuron's log firing rates in Hertz (Hz).
            </div>
        </div>

        <div class="row" id="BibTeX">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                If you find our data or project useful in your research, please cite:
                <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 10px">
@InProceedings{Zhang_2024_arXiv,
    author    = {Zhang, Yizi and Wang, Yanchen and Benetó, Donato Jiménez and Wang, Zixuan and Azabou, Mehdi and Richards, Blake and Winter, Olivier and The International Brain Laboratory and Dyer, Eva and Paninski, Liam and Hurwitz, Cole},
    title     = {Towards a “universal translator” for neural dynamics at single-cell, single-spike resolution},
    booktitle = {arXiv},
    month     = {July},
    year      = {2024},
    url       = {https://ibl-mtm.github.io}
}</pre>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgments
                </h3>
                The website template was borrowed from <a href="https://curvenet.github.io">Tiange Xiang</a>.
                <p></p>
            </div>
        </div>
    </div>


</body></html>
